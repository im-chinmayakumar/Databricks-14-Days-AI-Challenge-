# Databricks 14 Days AI Challenge ğŸš€

This repository documents my **daily learnings, notes, and hands-on implementations**
from the **Databricks 14 Days AI Challenge**.

The goal of this challenge is to build strong foundations in **Databricks, Apache Spark,
and data engineering concepts** through consistent daily practice.

---

## ğŸ“‚ Repository Structure

Each `Day-XX` folder contains:
- A `README.md` explaining the concepts learned
- Code files (`.py` / notebooks) with hands-on implementation

---

## ğŸ”§ Tools & Technologies
- Databricks
- Apache Spark
- PySpark
- SQL
- Delta Lake
- Lakehouse Architecture

---

## ğŸ¯ Learning Objectives
- Understand distributed data processing using Spark
- Gain hands-on experience with Databricks notebooks
- Apply data transformations on real-world datasets
- Build reliable and scalable data pipelines
- Maintain a well-documented learning repository

---

## ğŸ“… Challenge Progress

### âœ… Phase 1: Foundations (Completed)
- âœ… Day 01: Databricks Overview & Lakehouse Architecture  
- âœ… Day 02: Apache Spark Fundamentals  
- âœ… Day 03: PySpark Transformations Deep Dive  
- âœ… Day 04: Delta Lake Introduction  

### â³ Upcoming (Next Phases)
- Spark SQL & Advanced Queries  
- Performance Optimization  
- Delta Lake Advanced Features  
- End-to-End Data Pipelines  

---

## ğŸ”— Connect
This repository is part of my **learning-in-public journey**.  
Progress and insights are shared regularly on LinkedIn.
